[
 {kernel, [
    {logger_level, info},
    {logger, [
        %% Console handler for foreground modes (rebar3 shell, TUI)
        {handler, default, logger_std_h, #{
            level => info,
            formatter => {logger_formatter, #{
                template => [time, " [", level, "] ", msg, "\n"]
            }}
        }},
        %% File handler for daemon mode (stdout goes nowhere with -detached)
        {handler, file, logger_std_h, #{
            level => debug,
            config => #{
                file => "/tmp/beamclaw_daemon.log",
                max_no_bytes => 5242880,       %% 5 MB per file
                max_no_files => 3              %% keep 3 rotated files
            },
            formatter => {logger_formatter, #{
                template => [time, " [", level, "] ", msg, "\n"]
            }}
        }}
    ]}
 ]},
 {beamclaw_core, [
    {default_provider, openrouter},
    {providers, [
        {openrouter, #{api_key  => {env, "OPENROUTER_API_KEY"},
                       base_url => "https://openrouter.ai/api/v1",
                       model    => "moonshotai/kimi-k2.5"}},
        {openai, #{api_key  => {env, "OPENAI_API_KEY"},
                   base_url => "https://api.openai.com/v1",
                   model    => "gpt-4o"}}
    ]},
    {agentic_loop, #{max_tool_iterations => 10,
                     compaction_threshold => 50,
                     compaction_target    => 20,
                     stream_chunk_size    => 80}},
    {autonomy_level, supervised},
    {session_ttl_seconds, 3600},
    {default_agent, <<"default">>},
    {skills, #{}}
 ]},
 {beamclaw_mcp, [
    {servers, []}
 ]},
 {beamclaw_gateway, [
    {http, #{port => 8080}},
    {channels, [
        {telegram, #{token => {env, "TELEGRAM_BOT_TOKEN"}, mode => long_poll}},
        {tui,      #{enabled => true}}
    ]}
 ]},
 {beamclaw_obs, []},
 {beamclaw_memory, [
    {backend, ets}
 ]}
].
